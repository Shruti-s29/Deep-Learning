{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for neural network without hidden layer - Only Forward propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (4, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# created input vector, taking example of AND gate\n",
    "x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "# output \n",
    "# we have to make it 2D array and take the transpose so it becomes easy for calculation\n",
    "y = np.array([[0,0,0,1]]).T\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic neural network consists of input layer , summazation of weighted inputs , activation function and output.\n",
    "We will use Sigmoid function as activation function, and initialize weights randomly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are not using any hidden layer this means we are effectively applying/implementing logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here z is mx+b\n",
    "def sigmoid_func(z):\n",
    "    return 1/(1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.43428846],\n",
       "       [ 0.34239891]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intializing Weights \n",
    "# this takes input as the size/shape of array (here 2 rows and 1 col)\n",
    "# to change the ranges -\n",
    "## multiply with 2 so range becomes [0,2]\n",
    "## then substracting 1 means making [-1,1]\n",
    "\n",
    "weights = 2* np.random.random((2,1)) -1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5789867])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# biases\n",
    "# we want a single bias for this , for hidden layer the number will change accordingly\n",
    "bias = 2* np.random.random(1) -1\n",
    "bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction - 1\n",
      "Prediction - 1\n",
      "Prediction - 1\n",
      "Prediction - 1\n"
     ]
    }
   ],
   "source": [
    "# main  (prediction) ( forward propogation)\n",
    "\n",
    "def main(input,weights,bias):\n",
    "    # summation - matrix multiplication with weights\n",
    "    # dot product = mx\n",
    "    summ = np.dot(input,weights)\n",
    "\n",
    "    # z of sigmoid function = mx + b\n",
    "    z = summ + bias\n",
    "\n",
    "    out = sigmoid_func(z)\n",
    "    out\n",
    "\n",
    "    # for the concept of logistic regression if z >= 0.5 predict 1 , z<0.5 predict 0\n",
    "    for val in out:\n",
    "        if val >= float(0.5):\n",
    "            print('Prediction - 1')\n",
    "        else:\n",
    "            print('Prediction - 0')\n",
    "\n",
    "# call\n",
    "main(x,weights,bias)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the random weights are not predicting good, that is why we need hidden layer and error check and back propogation to continuously update weights and bias to reach the perfect accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_sig(z):\n",
    "    return sigmoid_func(z) * (1- sigmoid_func(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction - 0\n",
      "Prediction - 0\n",
      "Prediction - 0\n",
      "Prediction - 1\n"
     ]
    }
   ],
   "source": [
    "# iterating 10000 to meet the convergence of gradient descent\n",
    "\n",
    "for iteration in range(10000):\n",
    "        input = x\n",
    "        out = sigmoid_func(np.dot(input,weights) + bias)\n",
    "\n",
    "        # Gradient \n",
    "        #learning rate\n",
    "        lr = 0.001\n",
    "        first_term = out - y\n",
    "\n",
    "        z = np.dot(input,weights) + bias\n",
    "        second_term = derivative_sig(z)\n",
    "\n",
    "        first_two = first_term * second_term\n",
    "\n",
    "\n",
    "        #third term is basically features only\n",
    "\n",
    "        # CHANGING WEIGHTS\n",
    "        changes = np.array([[0.0],[0.0]])\n",
    "        # we will use these changes to update weights\n",
    "\n",
    "        for i in range(2):\n",
    "                for j in range(4):\n",
    "                        changes[i][0] += first_two[j][0] * input[j][i]\n",
    "\n",
    "        # updating weights \n",
    "\n",
    "        weights = weights - lr*changes\n",
    "\n",
    "        # CHANGING BIAS\n",
    "        bias_change = 0.0\n",
    "        for j in range(4):\n",
    "                bias_change += first_two[j][0] * 1\n",
    "        bias = bias - lr*bias_change\n",
    "\n",
    "# calling main\n",
    "main(x,weights,bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
